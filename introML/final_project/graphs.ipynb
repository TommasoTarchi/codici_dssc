{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grafici"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for the dataset\n",
    "import pandas as pd    \n",
    "import numpy as np\n",
    "\n",
    "# general\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_validate\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.metrics import accuracy_score\n",
    "import time\n",
    "\n",
    "# for the tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import tree\n",
    "\n",
    "# for the Random forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# for the SVM + packages for pipelines and scaling\n",
    "from sklearn import svm\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# for the Gaussian\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# for KNN\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# to print more results and not just the last one\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = 'all'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dataset\n",
    "\n",
    "# setting up labels for dataset\n",
    "labels = ('class', 'spec_num', 'eccentr', 'asp_ratio', 'elong', 'solidity', 'stoch_conv', 'iso_factor', 'max_ind_depth', 'lobedness', 'av_intensity', 'av_contr', 'smooth', 'third_mom', 'unif', 'entropy')\n",
    "\n",
    "# importing data\n",
    "df = pd.read_csv(r'./leaf/leaf.csv', header = None, names = labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for training and testing static division, if needed\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=100)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NON SERVE RUNNARE\n",
    "# ho considerato i parametri riportati nell'ultima riga\n",
    "\n",
    "#Grid Search - finding best estimators\n",
    "\n",
    "# shuffling the dataframe + separating y from x + eliminating specimen number variable\n",
    "df = df.sample(frac=1).reset_index()\n",
    "df = df.iloc[:, 1:17]   # needed to eliminate the old indexes column\n",
    "X = df.iloc[:, 2:16]\n",
    "y = df.iloc[:, 0]\n",
    "\n",
    "# griglia dei parametri su cui fare la ricerca\n",
    "# for n-min in proglie c'è da 2 a 40, ma forse 40 è troppo alto visto che le osservazioni sono meno di 400\n",
    "grid_param = {'criterion': ['gini', 'entropy'], 'min_samples_split': np.arange(2, 20)}\n",
    "\n",
    "tree_cv = GridSearchCV(tree.DecisionTreeClassifier(), grid_param, cv=8, scoring='balanced_accuracy')\n",
    "tree_cv.fit(X, y)\n",
    "print(tree_cv.best_score_)   #result: 0.6791666666666667\n",
    "print(tree_cv.best_params_)  #result: {'criterion': 'entropy', 'min_samples_split': 4}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dati per grafico Single Tree - tentativo 1\n",
    "\n",
    "TREE = []\n",
    "\n",
    "for i in range(50):\n",
    "    # shuffling the dataframe\n",
    "    df = df.sample(frac=1).reset_index()\n",
    "    df = df.iloc[:, 1:17]   # needed to eliminate the old indexes column\n",
    "    # separating y from x and eliminating specimen number variable\n",
    "    X = df.iloc[:, 2:16]\n",
    "    y = df.iloc[:, 0]\n",
    "    clf_T1 = cross_validate(DecisionTreeClassifier(criterion = \"entropy\", min_samples_split = 4), X, y, cv=8, scoring = \"balanced_accuracy\")\n",
    "    scores_tree = np.mean(clf_T1[\"test_score\"])\n",
    "    TREE.append(scores_tree)\n",
    "    \n",
    "print(TREE)\n",
    "print(np.mean(TREE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time_tree = time.time()\n",
    "cross_validate(DecisionTreeClassifier(criterion = \"entropy\", min_samples_split = 4), X, y, cv=8, scoring = \"balanced_accuracy\")\n",
    "stop_time_tree = time.time()\n",
    "print(\"Process finished in %s seconds\" % (stop_time_tree - start_time_tree))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NON SERVE RUNNARE\n",
    "# ho considerato i parametri riportati nell'ultima riga\n",
    "\n",
    "# Grid Search - finding best estimators\n",
    "\n",
    "# shuffling the dataframe + separating y from x + eliminating specimen number variable\n",
    "df = df.sample(frac=1).reset_index()\n",
    "df = df.iloc[:, 1:17]   # needed to eliminate the old indexes column\n",
    "X = df.iloc[:, 2:16]\n",
    "y = df.iloc[:, 0]\n",
    "\n",
    "# griglia dei parametri su cui fare la ricerca\n",
    "grid_param = {\"n_estimators\": (100, 200, 500, 700, 900), 'criterion': ('gini', 'entropy')}\n",
    "\n",
    "rf_cv = GridSearchCV(RandomForestClassifier(max_features=4), grid_param, cv=8, scoring='balanced_accuracy', n_jobs=5)\n",
    "rf_cv.fit(X, y)\n",
    "print(rf_cv.best_score_)    #result: 0.8145833333333333\n",
    "print(rf_cv.best_params_)   #result: {'criterion': 'gini', 'n_estimators': 200}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dati per grafico Random Forest - tentativo 1\n",
    "\n",
    "RAN_FOR = []\n",
    "\n",
    "for i in range(50):\n",
    "    # shuffling the dataframe\n",
    "    df = df.sample(frac=1).reset_index()\n",
    "    df = df.iloc[:, 1:17]   # needed to eliminate the old indexes column\n",
    "    # separating y from x and eliminating specimen number variable\n",
    "    X = df.iloc[:, 2:16]\n",
    "    y = df.iloc[:, 0]\n",
    "    clf_RF1 = cross_validate(RandomForestClassifier(n_estimators = 200, criterion = \"gini\", max_features=4), X, y, cv=8, scoring = \"balanced_accuracy\", n_jobs = 5)\n",
    "    scores_RF = np.mean(clf_RF1[\"test_score\"])\n",
    "    RAN_FOR.append(scores_RF)\n",
    "print(RAN_FOR)\n",
    "print(np.mean(RAN_FOR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#timing\n",
    "\n",
    "start_time_rf = time.time()\n",
    "cross_validate(RandomForestClassifier(n_estimators = 200, criterion = \"gini\", max_features= \"sqrt\"), X, y, cv=8, scoring = \"balanced_accuracy\", n_jobs = 5)\n",
    "stop_time_rf = time.time()\n",
    "print(\"Process finished in %s seconds\" % (stop_time_rf - start_time_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dati per grafico Random Forest - tentativo 2\n",
    "\n",
    "#RF=[]\n",
    "\n",
    "#for i in range(1, 6):\n",
    "    #clf_RF2 = RandomForestClassifier(n_estimators = 700, criterion = \"entropy\", max_features = 5)\n",
    "    #clf_RF2.fit(X_train,y_train)\n",
    "    #predictions = clf_RF2.predict(X_test)\n",
    "    #RF.append(accuracy_score(y_test, predictions))\n",
    "\n",
    "#print(RF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NON SERVE RUNNARE\n",
    "# ho considerato i parametri riportati nell'ultima riga\n",
    "\n",
    "# Grid Search - finding best estimators\n",
    "\n",
    "# building the pipeline\n",
    "pipe = Pipeline([('scaling', StandardScaler()),\n",
    "                 ('SVM', svm.SVC(decision_function_shape='ovo'))])\n",
    "\n",
    "# building the range of the regularization parameter (C) and of gamm\n",
    "reg_param = np.logspace(-10, 11, 22)\n",
    "gamm = np.logspace(-9, 3, 13)\n",
    "\n",
    "grid_param = {'SVM__C': reg_param,\n",
    "              'SVM__kernel': ('linear', 'poly', 'rbf', 'sigmoid'), \n",
    "              'SVM__degree': np.arange(2, 5),\n",
    "              'SVM__decision_function_shape': ('ovo', 'ovr'),\n",
    "              'SVM__gamma': gamm}\n",
    "\n",
    "# shuffling the dataframe\n",
    "df = df.sample(frac=1).reset_index()\n",
    "df = df.iloc[:, 1:17]   # needed to eliminate the old indexes column\n",
    "# separating y from x and eliminating specimen number variable\n",
    "X = df.iloc[:, 2:16]\n",
    "y = df.iloc[:, 0]\n",
    "\n",
    "svm_cv = GridSearchCV(pipe, grid_param, cv=8, scoring='balanced_accuracy', n_jobs=5)\n",
    "svm_cv.fit(X,y)\n",
    "\n",
    "print(svm_cv.best_score_)  # result: 0.8104166666666666\n",
    "print(svm_cv.best_params_) # result: {'SVM__C': 100000.0, 'SVM__decision_function_shape': 'ovo', 'SVM__degree': 2, 'SVM__gamma': 0.0001, 'SVM__kernel': 'rbf'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dati per grafico SVM\n",
    "\n",
    "SVM = []\n",
    "\n",
    "pipe = Pipeline([('scaling', StandardScaler()),\n",
    "                 ('SVM', svm.SVC( C= 100000.0, decision_function_shape = \"ovo\", degree = 2, gamma = 0.0001, kernel = \"rbf\"))])\n",
    "\n",
    "for i in range(50):\n",
    "    # shuffling the dataframe\n",
    "    df = df.sample(frac=1).reset_index()\n",
    "    df = df.iloc[:, 1:17]   # needed to eliminate the old indexes column\n",
    "    # separating y from x and eliminating specimen number variable\n",
    "    X = df.iloc[:, 2:16]\n",
    "    y = df.iloc[:, 0]\n",
    "    clf_SVM1 = cross_validate(pipe, X, y, cv=8, scoring = \"balanced_accuracy\")\n",
    "    scores_SVM1 = np.mean(clf_SVM1[\"test_score\"])\n",
    "    SVM.append(scores_SVM1)\n",
    "\n",
    "print(SVM)\n",
    "print(np.mean(SVM))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#timing\n",
    "\n",
    "start_time_svm = time.time()\n",
    "cross_validate(pipe, X, y, cv=8, scoring = \"balanced_accuracy\")\n",
    "stop_time_svm = time.time()\n",
    "print(\"Process finished in %s seconds\" % (stop_time_svm - start_time_svm))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# No grid search since we don't have any hyper-parameters to choose\n",
    "\n",
    "# shuffling the dataframe\n",
    "df = df.sample(frac=1).reset_index()\n",
    "df = df.iloc[:, 1:17]   # needed to eliminate the old indexes column\n",
    "# separating y from x and eliminating specimen number variable\n",
    "X = df.iloc[:, 2:16]\n",
    "y = df.iloc[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dati per grafico Naive Bayes\n",
    "\n",
    "# k-fold cross validation\n",
    "\n",
    "NB = []\n",
    "\n",
    "for i in range(50):\n",
    "    # shuffling the dataframe\n",
    "    df = df.sample(frac=1).reset_index()\n",
    "    df = df.iloc[:, 1:17]   # needed to eliminate the old indexes column\n",
    "    # separating y from x and eliminating specimen number variable\n",
    "    X = df.iloc[:, 2:16]\n",
    "    y = df.iloc[:, 0]\n",
    "    effect_NB_cv = cross_validate(GaussianNB(), X, y, cv= 8, scoring='balanced_accuracy')\n",
    "    scores_NB1 = np.mean(effect_NB_cv[\"test_score\"])\n",
    "    NB.append(scores_NB1)\n",
    "    \n",
    "print(NB)\n",
    "print(np.mean(NB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#timing\n",
    "\n",
    "start_time_nb = time.time()\n",
    "cross_validate(GaussianNB(), X, y, cv= 8, scoring='balanced_accuracy')\n",
    "stop_time_nb = time.time()\n",
    "print(\"Process finished in %s seconds\" % (stop_time_nb - start_time_nb))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NON SERVE RUNNARE\n",
    "# ho considerato i parametri riportati nell'ultima riga\n",
    "\n",
    "# Grid Search - finding best estimators\n",
    "\n",
    "# shuffling the dataframe\n",
    "df = df.sample(frac=1).reset_index()\n",
    "df = df.iloc[:, 1:17]   # needed to eliminate the old indexes column\n",
    "# separating y from x and eliminating specimen number variable\n",
    "X = df.iloc[:, 2:16]\n",
    "y = df.iloc[:, 0]\n",
    "\n",
    "# griglia dei parametri su cui fare la ricerca\n",
    "grid_param_cv = {'n_neighbors': np.arange(1, 340-340//8), 'metric': ('cosine', 'euclidean', 'manhattan')}\n",
    "\n",
    "knn_cv = GridSearchCV(KNeighborsClassifier(), grid_param_cv, cv= 8, scoring='balanced_accuracy', return_train_score=False, verbose=0, n_jobs= 5)\n",
    "knn_cv.fit(X, y)\n",
    "print(knn_cv.best_score_)  # result: 0.6354166666666666\n",
    "print(knn_cv.best_params_) # result: {'n_neighbors': 5, 'metric': manhattan}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dati per grafico KNN\n",
    "\n",
    "KNN = []\n",
    "\n",
    "for i in range(50):\n",
    "    # shuffling the dataframe\n",
    "    df = df.sample(frac=1).reset_index()\n",
    "    df = df.iloc[:, 1:17]   # needed to eliminate the old indexes column\n",
    "    # separating y from x and eliminating specimen number variable\n",
    "    X = df.iloc[:, 2:16]\n",
    "    y = df.iloc[:, 0]\n",
    "    clf_KNN1 = cross_validate(KNeighborsClassifier(n_neighbors = 5, metric = 'manhattan'), X, y, cv=8, scoring = \"balanced_accuracy\", n_jobs = 5)\n",
    "    scores_KNN1 = np.mean(clf_KNN1[\"test_score\"])\n",
    "    KNN.append(scores_KNN1)\n",
    "print(KNN)\n",
    "print(np.mean(KNN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#timing\n",
    "\n",
    "start_time_knn = time.time()\n",
    "cross_validate(KNeighborsClassifier( n_neighbors = 5, weights = \"distance\"), X, y, cv=8, scoring = \"balanced_accuracy\", n_jobs = 5)\n",
    "stop_time_knn = time.time()\n",
    "print(\"Process finished in %s seconds\" % (stop_time_knn - start_time_knn))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# for fancier plots\n",
    "import seaborn as sns\n",
    "sns.set_theme()\n",
    "sns.set(rc={\"axes.facecolor\": \"#eee7e5\", \"figure.facecolor\": \"eee7e5\"})\n",
    "\n",
    "scores_from_loop = [TREE, RAN_FOR, SVM, NB, KNN]\n",
    "labels = [\"Tree\", \"Random Forest\", \"SVM\", \"Naive Bayes\", \"KNN\"]\n",
    "colors = ['grey', 'blue', 'green', 'red', 'orange']\n",
    "colors2 = ['grey', 'grey', 'blue', 'blue', 'green', 'green', 'red', 'red', 'orange', 'orange']\n",
    "\n",
    "# Creating plot\n",
    "fig, (ax) = plt.subplots(figsize=(8, 6), edgecolor= \"blue\")\n",
    "\n",
    "bplot = ax.boxplot(scores_from_loop, \n",
    "                   vert=True,  # vertical box alignment\n",
    "                   patch_artist=False,  # fill with color\n",
    "                   labels=labels)  # will be used to label x-ticks\n",
    "                   \n",
    "dict_title = {'fontsize': 20, 'fontweight': 'bold'}\n",
    "#ax.set_title('Weighted accuracy', fontdict=dict_title)\n",
    "ax.set_xticklabels(labels=labels, rotation = 45, fontsize=13)\n",
    "ax.set_ylabel('weighted accuracy')\n",
    "\n",
    "for element in ['boxes', 'fliers', 'means', 'medians']:\n",
    "    for patch, color in zip(bplot[element], colors):\n",
    "        patch.set_color(color)\n",
    "\n",
    "for element in ('whiskers', 'caps'):\n",
    "    for patch, color in zip(bplot[element], colors2):\n",
    "        patch.set_color(color)\n",
    "\n",
    "# saving plot\n",
    "plt.savefig('boxplot.png')\n",
    "\n",
    "# show plot\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
