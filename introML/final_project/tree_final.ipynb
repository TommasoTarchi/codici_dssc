{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn import metrics    # contains all the effectivness idexes \n",
    "import pandas as pd    # for the dataset\n",
    "import numpy as np\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = 'all'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting up labels for dataset\n",
    "labels = ['class', 'spec_num', 'eccentr', 'asp_ratio', 'elong', 'solidity', 'stoch_conv', 'iso_factor', 'max_ind_depth', 'lobedness', 'av_intensity', 'av_contr', 'smooth', 'third_mom', 'unif', 'entropy']\n",
    "#importing data\n",
    "df = pd.read_csv(r'./leaf/leaf.csv', header = None, names = labels)\n",
    "# shuffling the dataframe\n",
    "df = df.sample(frac=1).reset_index()\n",
    "df = df.iloc[:, 1:17]   # needed to eliminate the old indexes column\n",
    "#separating y from x\n",
    "X = df.iloc[:, 2:16]\n",
    "y = df.iloc[:, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### finding best hyper-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# names of all effectivness indexes available in sklearn\n",
    "\n",
    "# note that roc_auc doesn't work in cv because it is a multiclass classification (we need to specify\n",
    "# ovo or ovr) and that all roc_auc variants don't work in loocv because the testing sets contain\n",
    "# only one observation\n",
    "\n",
    "print(metrics.get_scorer_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using grid search with k-fold CV to find the best hyperparameters and fitting the tree\n",
    "\n",
    "# se refit = 'blabla', alla fine viene rifittato l'albero su tutto il dataset scegliendo i parametri\n",
    "# migliori in base all'indice di accuracy 'blabla'\n",
    "\n",
    "k = 5\n",
    "\n",
    "# griglia dei parametri su cui fare la ricerca\n",
    "grid_param = {'criterion': ['gini', 'entropy'], 'min_samples_split': np.arange(2, 15)}\n",
    "\n",
    "# 'preparazione' indici di effectivness\n",
    "# si usa la funzione make_scorer per costruire le metriche che ci servono\n",
    "b_accuracy = metrics.make_scorer(metrics.balanced_accuracy_score)\n",
    "recall = metrics.make_scorer(metrics.recall_score, average='weighted')\n",
    "auc_ovo = metrics.make_scorer(metrics.roc_auc_score, multi_class='ovo', needs_proba=True, average='weighted')\n",
    "auc_ovr = metrics.make_scorer(metrics.roc_auc_score, multi_class='ovr', needs_proba=True, average='weighted')\n",
    "scorers = {'balanced_accuracy': b_accuracy, 'recall': recall, 'roc_auc_ovo': auc_ovo, 'roc_auc_ovr': auc_ovr}\n",
    "\n",
    "clf_cv = GridSearchCV(tree.DecisionTreeClassifier(), grid_param, cv=k, scoring=scorers, refit=False)\n",
    "clf_cv.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# showing the mean values of effectivness indexes\n",
    "\n",
    "results_cv = pd.DataFrame(clf_cv.cv_results_)\n",
    "\n",
    "display(results_cv.loc[:, ('params', 'mean_test_balanced_accuracy', 'rank_test_balanced_accuracy', 'mean_test_recall', 'rank_test_recall', 'mean_test_roc_auc_ovo', 'rank_test_roc_auc_ovo', 'mean_test_roc_auc_ovr', 'rank_test_roc_auc_ovr')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using now grid search with loocv\n",
    "\n",
    "clf_loocv = GridSearchCV(tree.DecisionTreeClassifier(), grid_param, cv=LeaveOneOut(), scoring='accuracy')\n",
    "clf_loocv.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"best parameters: \" + str(clf_loocv.best_params_))\n",
    "print(\"accuracy loocv: \" + str(clf_loocv.best_score_))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
