{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J9COPEtjM_db"
      },
      "source": [
        "# Notebook 1: **Probability** basics\n",
        "\n",
        "Probabilistic Machine Learning -- Spring 2023, UniTS\n",
        "\n",
        "<a target=\"_blank\" href=\"https://colab.research.google.com/github/emaballarin/probml-units/blob/main/notebooks/01_probability_basics.ipynb\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open in Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [],
        "id": "BsM8_h4rM_de"
      },
      "source": [
        "### Random variables\n",
        "\n",
        "**Measurable space** $(\\Omega,\\mathcal{F})$:\n",
        "\n",
        "- $\\Omega$ is a set;\n",
        "- $\\mathcal{F}$ is a $\\sigma$-algebra on $\\Omega$, i.e. $\\mathcal{F}$:\n",
        "    - contains $\\emptyset, \\Omega$;\n",
        "    - is closed under complementary sets;\n",
        "    - is closed under countable unions.\n",
        "\n",
        "\n",
        "**Measurable function** $f$:\n",
        "\n",
        "- $f:(\\Omega_1,\\mathcal{F}_1)\\rightarrow (\\Omega_2,\\mathcal{F}_2)$;\n",
        "- The pre-image $f^{-1}(E)$, $\\forall$ measurable set $E\\in\\mathcal{F}_2$, is measurable (i.e. $f^{-1}(E)\\in\\mathcal{F}_1$).\n",
        "\n",
        "\n",
        "**Probability measure** $P$ on $(\\Omega,\\mathcal{F})$:\n",
        "\n",
        "- $P:\\mathcal{F}\\rightarrow [0,1]$;\n",
        "- $P$ is countably additive on pairwise disjoint sets;\n",
        "- $P(\\emptyset)=0$ and $P(\\Omega)=1$.\n",
        "\n",
        "\n",
        "**Random variable** $X$:\n",
        "\n",
        "- $(\\Omega,\\mathcal{F},P)$ probability space;\n",
        "- $(\\mathcal{X},\\mathcal{A})$ measurable space;\n",
        "- Measurable $X:(\\Omega,\\mathcal{F},P)\\rightarrow (\\mathcal{X},\\mathcal{A})$.\n",
        "\n",
        "$X$ induces the push-forward probability measure $\\mu$ on $\\mathcal{X}$: $\\mu(A):=X_*P(A)=P(X\\in A) := P(X^{-1}(A))$ for any $A\\in\\mathcal{A}$.\n",
        "\n",
        "\n",
        "**Probability mass function** $p_X$\n",
        "\n",
        "- Finite or countable $\\mathcal{X}$;\n",
        "- $p_X(x):=P(X=x)$ for $x\\in\\mathcal{X}$.\n",
        "\n",
        "\n",
        "**Probability density function** $f_X$:\n",
        "\n",
        "- Infinite $\\mathcal{X}$;\n",
        "- Measurable function $f_X:\\mathcal{X}\\rightarrow[0,+\\infty)$;\n",
        "- $P(a \\leq X \\leq b) = \\int_a^b f_X(x)dx$.\n",
        "\n",
        "It follows that $\\int_\\mathbb{R} f_X(x)dx=1$.\n",
        "\n",
        "\n",
        "### Notable probability distributions\n",
        "\n",
        "\n",
        "| discrete distribution | *pmf* | mean | variance |\n",
        "| :--------------------:|:-----:|:----:|:--------:|\n",
        "| Binomial $$\\text{Bin}(n,p)$$ | $$ {n \\choose x} p^x (1-p)^{n-x}$$ | $$np$$ | $$np(1-p)$$ |\n",
        "| Bernoulli $$\\text{Bern}(p)$$| $$\\begin{cases}1-p &k=1\\\\ 0&k=0\\end{cases}$$ | $$p$$ |$$p(1-p)$$ |\n",
        "| Discrete Uniform $$\\mathcal{U}(a,b)$$ | $$\\frac{1}{b-a+1}$$ | $$\\frac{b+a}{2}$$ |$$\\frac{(b-a+1)^2-1}{12}$$ |\n",
        "| Geometric $$\\text{Geom}(p)$$ | $(1-p)^{k-1}p$ |$$\\frac{1}{p}$$|$$\\frac{1-p}{p^2}$$ |\n",
        "| Poisson $$\\text{Pois}(\\lambda)$$ |$$\\frac{\\lambda^k e^{-\\lambda}}{k!}$$|$$\\lambda$$ | $$\\lambda$$ |\n",
        "\n",
        "where:\n",
        "- $n\\in\\{0,1,2,...\\}$\n",
        "- $p \\in [0,1]$ or $p \\in (0,1)$\n",
        "- $b\\geq a$\n",
        "- $k\\in\\{1,2,3,...\\}$\n",
        "- $\\lambda \\in \\mathbb{R}^+$\n",
        "\n",
        "| continuous distribution | *pdf* | mean | variance |\n",
        "| :----------------------:|:-----:|:----:|:--------:|\n",
        "| Continuous Uniform $$\\mathcal{U}(a,b)$$|$$\\begin{cases}\\frac{1}{b-a} & x \\in [a,b]\\\\0 & \\text{otherwise}\\end{cases}$$|$$\\frac{a+b}{2}$$|$$\\frac{(b-a)^2}{12}$$ |\n",
        "| Exponential $$\\text{Exp}(\\lambda)$$|$$\\lambda e^{-\\lambda x}$$|$$1/\\lambda$$|$$1/\\lambda^2$$ |\n",
        "| Gaussian $$\\mathcal{N}(\\mu,\\sigma^2)$$|$$\\frac{1}{\\sigma\\sqrt{2\\pi}}e^{-\\frac{1}{2}\\big(\\frac{x-\\mu}{\\sigma}\\big)^2}$$|$$\\mu$$|$$\\sigma^2$$|\n",
        "|Beta $$\\text{Beta}(\\alpha,\\beta)$$|$$\\frac{x^{\\alpha-1}(1-x)^{\\beta-1}}{B(\\alpha,\\beta)}$$|$$\\frac{\\alpha}{\\alpha+\\beta}$$|$$\\frac{\\alpha\\beta}{(\\alpha+\\beta)^2(\\alpha+\\beta+1)}$$| \n",
        "|Gamma $$\\text{Gamma}(\\alpha, \\beta)$$|$$\\frac{\\beta^\\alpha}{\\Gamma(\\alpha)}x^{\\alpha-1}e^{-\\beta x}$$|$$\\frac{\\alpha}{\\beta}$$|$$\\frac{\\alpha}{\\beta^2}$$|\n",
        "|Dirichlet $$Dir(\\alpha)$$|$$\\frac{1}{B(\\alpha)}\\prod_{i=1}^{K}x_i^{\\alpha_i-1}$$|$$\\tilde{\\alpha}_i$$|$$\\frac{\\tilde{\\alpha}_i(1-\\tilde{\\alpha}_i)}{\\alpha_0+1}$$ |\n",
        "|Student's t $$St(\\nu)$$| $$\\frac{\\Gamma(\\frac{\\nu+1}{2})}{\\sqrt{\\nu\\pi}\\Gamma(\\frac{\\nu}{2})}{\\Big(1+\\frac{x^2}{\\nu}\\Big)^{-\\frac{\\nu+1}{2}}}$$ |$$0$$|$$\\begin{cases}\\frac{\\nu}{\\nu-2}&\\nu>2\\\\\\infty&1<\\nu\\leq2\\end{cases}$$ |\n",
        "\n",
        "where:\n",
        "- $b \\geq a$\n",
        "- $\\lambda \\in \\mathbb{R}^+$\n",
        "- $\\mu,\\sigma,\\alpha,\\beta\\in\\mathbb{R}$\n",
        "- $\\alpha,\\beta>0$ for the Gamma distribution\n",
        "- $k,\\theta > 0$\n",
        "- $K\\in\\mathbb{Z}_{\\geq2}$\n",
        "- $\\tilde{\\alpha}_i=\\frac{\\alpha_i}{\\sum_{h=1}^K\\alpha_h}$, $\\alpha_0=\\sum_{i=1}^K \\alpha_i$\n",
        "- $\\nu>1$\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [],
        "id": "efoC3LOFM_dk"
      },
      "source": [
        "### Expected value\n",
        "\n",
        "**Definition**\n",
        "\n",
        "Let $X:(\\Omega,\\mathcal{F},P)\\longrightarrow (\\mathcal{X},\\mathcal{A})$ be a random variable.\n",
        "\n",
        "|values|expectation $E[X]$|\n",
        "|:----:|:----------------:|\n",
        "|finite| $$\\sum_{i=1}^k x_i p_X(x_i)$$|\n",
        "|countable|$$\\sum_{i=1}^\\infty x_i p_X(x_i)$$|\n",
        "|continuous|$$\\int_{\\mathbb{R}}x f_X(x)dx$$|\n",
        "\n",
        "where $p_X$ is the probability mass function of $X$ in the discrete case and $f_X$ is the probability density function of $X$ in the continuous case. \n",
        "\n",
        "**Example: discrete case**\n",
        "\n",
        "Let $Y$ be a discrete random variable with values in $\\{0,1\\}$ and let $P(Y=1)=p$. Suppose we want to compute the expectation $\\mathbb{E}[|Y-p|]$.\n",
        "\n",
        "From the definition of expectation we know that, in the discrete case, we just need to multiply each possible value that the random variable can assume by its probability of occurring:\n",
        "\n",
        "$$\n",
        "\\mathbb{E}[|Y-p|] = p(1-p) + (1-p) p = 2p(1-p)\n",
        "$$\n",
        "\n",
        "**Example: continuous case**\n",
        "\n",
        "Let the pdf of $X$ be \n",
        "\n",
        "$$f(x)=\\begin{cases}cx^2(1-x) & 0\\leq x \\leq 1\\\\ 0 & \\text{otherwise}\\end{cases}$$\n",
        "\n",
        "We want to determine $c\\in\\mathbb{R}$ such that $f(x)$ is a valid *pdf*:\n",
        "\n",
        "$$1 =\\int_0^1 cx^2(1-x)dx = c \\int_0^1 (x^2-x^3)dx = c\\Big[\\frac{x^3}{3}-\\frac{x^4}{4}\\Big]_0^1 = \\frac{c}{12} $$\n",
        "\n",
        "$$\\Longrightarrow c=12$$\n",
        "\n",
        "Now we compute the expected value of $X$:\n",
        "\n",
        "$$E[X]=12\\int_0^1x^3(1-x)dx=12\\Big[\\frac{x^4}{4}-\\frac{x^5}{5}\\Big]_0^1=\\frac{3}{5}$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "20fAHd7YM_dm"
      },
      "source": [
        "### Covariance and correlation\n",
        "\n",
        "**Covariance** measures the common variation of $X$ and $Y$. \n",
        "It is defined as $\\text{cov}(X,Y)=\\mathbb{E}[(X-\\mathbb{E}[X])(Y-\\mathbb{E}[Y])] = \\mathbb{E}[XY]-\\mathbb{E}[X]\\mathbb{E}[Y].$\n",
        "\n",
        "The covariance of a random variable with itself is called **variance**: $\\text{var}(X)=\\text{cov}(X,X)=\\mathbb{E}[X-\\mathbb{E}(X)^2]$.\n",
        "\n",
        "The **correlation coefficient** between $X$ and $Y$ is the normalized covariance: $\\displaystyle{\\rho=\\frac{\\text{cov}(X,Y)}{\\sqrt{\\text{var}(X)\\text{var}(Y)}}}$. \n",
        "\n",
        "The two variables are said to be *perfectly correlated* when $\\rho=1$ and *anti-correlated* when $\\rho=-1$.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1hQWgn--M_dn"
      },
      "source": [
        "### Marginal and conditional distributions\n",
        "\n",
        "**Definitions**\n",
        "\n",
        "Multiple random variables $X_1,\\ldots, X_N$ on the same probability space define a **multivariate random variable**, whose **joint probability mass function** is -- in the discrete case:\n",
        "\n",
        "$$p_{X_1,\\ldots, X_N}(x_1,\\ldots, x_N)=P(X_1=x_1,\\ldots,X_N=x_N)$$\n",
        "\n",
        "\n",
        "While the **joint probability density function** is -- in the continuous case:\n",
        "\n",
        "$$P(X_1\\in[a_1,b_1],\\ldots, X_N\\in[a_N,b_N])=\\int_{a_1}^{b_1}\\ldots\\int_{a_N}^{b_N}f_{X_1,\\ldots, X_N}(x_1,\\ldots,x_N)dx_1\\ldots dx_N$$\n",
        "\n",
        "\n",
        "![](https://github.com/emaballarin/probml-units/blob/main/notebooks/img/multivariate_normal_sample.png?raw=1)\n",
        "<br><sub><sup>From <a href=\"https://en.wikipedia.org/wiki/Joint_probability_distribution\">Wikipedia: Joint probability distribution</a></sup></sub>\n",
        "\n",
        "\n",
        "In the bivariate case, for example, we can derive marginal and conditional distributions from the joint distribution as follows: \n",
        "\n",
        "|$X$ values|marginal distribution| conditional distribution|\n",
        "|:--------:|:-------------------------------------------------:|:-----------------------:|\n",
        "| discrete | $$p_X(x)=\\sum_{y\\in{\\mathcal{X}_Y}}p_{X,Y}(x,y)$$ | $$ p_{Y\\|X}(y\\|x) = \\frac{p_{X,Y}(x,y)}{p_X(x)} $$ |\n",
        "| continuous | $$f_X(x)=\\int_{\\mathcal{X_Y}}f_{X,Y}(x,y)dy$$ | $$ f_{Y\\|X}(y\\|x) = \\frac{f_{X,Y}(x,y)}{f_X(x)} $$ |\n",
        "\n",
        "These definitions easily extend to the multivariate case.\n",
        "\n",
        "\n",
        "Two *r.v.*s $X,Y$ are **independent** if and only if their joint probability equals the product of the marginal probabilities\n",
        "\n",
        "$$f_{X,Y}(x,y)=f_X(x)f_Y(y).$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6aHUDWGOM_do"
      },
      "source": [
        "**Example: marginal and conditional from the joint**\n",
        "\n",
        "Let $X$ and $Y$ be two discrete random variables with joint probability distribution\n",
        "$$\n",
        "p(x,y) = \\frac{1}{21}(x+y)\n",
        "$$\n",
        "for $x=1,2,3$ and $y=1,2$.\n",
        "\n",
        "The marginal distribution of $X$ is:\n",
        "$$\n",
        "p_X(x) = \\sum_{y=1}^2 p(x,y) = \\sum_{y=1}^2 \\frac{1}{21}(x+y) = \\frac{1}{21}(2x+3)\n",
        "$$\n",
        "for $x=1,2,3$.\n",
        "\n",
        "The conditional distribution of $Y$ given $X=1$ is:\n",
        "\n",
        "$$\n",
        "p_{Y|X}(y|1)=\\frac{p(1,y)}{p_X(1)}= \\frac{\\frac{1}{21}(1+y)}{\\frac{5}{21}} = \\frac{1}{5}(1+y)\n",
        "$$\n",
        "\n",
        "for $y=1,2$.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "siAM4j1YM_dp"
      },
      "source": [
        "### Conditional independence\n",
        "\n",
        "The **cumulative distribution function** of $X$ is defined as $F_X(x)=P(X\\leq x)$.\n",
        "\n",
        "Two random variables $X$ and $Y$ are **conditionally independent** given $Z$ if and only if \n",
        "\n",
        "$$\n",
        "F_{X,Y|Z=z}(x,y)=F_{X|Z=z}(x)\\cdot F_{Y|Z=z}(y)\n",
        "$$\n",
        "\n",
        "for all $x,y,z$, where $F_{X,Y|Z=z}(x,y)=P(X\\leq x, Y\\leq y|Z=z)$ is the conditional c.d.f. of $X,Y|Z$.\n",
        "\n",
        "\n",
        "### Law of total probability\n",
        "\n",
        "Let $\\{B_n\\}_{n\\in I}$ be a partition of the sample space, then for any event $A$ in the same probability space:\n",
        "\n",
        "$$P(A) = \\sum_{n\\in I} P(A,B_n) = \\sum_{n \\in I}P(A|B_n)P(B_n).$$\n",
        "\n",
        "In other words, one can compute the probability of an event $A$ by conditioning on all the possible cases belonging to a partition of the sample space."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AJJfaExOM_dp"
      },
      "source": [
        "## References\n",
        "-  [J. Jacod, P. Protter, \"Probability Essentials\"](https://zero.sci-hub.ru/6098/787f72eac157546be3d98fcc129b8ba6/jacod2004.pdf)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}